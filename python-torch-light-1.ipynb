{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T08:21:23.865576Z","iopub.execute_input":"2024-01-02T08:21:23.866279Z","iopub.status.idle":"2024-01-02T08:21:26.785161Z","shell.execute_reply.started":"2024-01-02T08:21:23.866242Z","shell.execute_reply":"2024-01-02T08:21:26.784275Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    # Get the number of available GPUs\n    num_gpus = torch.cuda.device_count()\n    print(f\"Number of available GPUs: {num_gpus}\")\n\n    # Get the name of each GPU\n    for i in range(num_gpus):\n        gpu_name = torch.cuda.get_device_name(i)\n        print(f\"GPU {i}: {gpu_name}\")\n\n    # Get the current GPU device\n    current_device = torch.cuda.current_device()\n    print(f\"Current GPU device: {current_device}\")\n\n    # Get GPU properties\n    gpu_properties = torch.cuda.get_device_properties(current_device)\n    print(f\"GPU Properties:\\n{gpu_properties}\")\nelse:\n    print(\"No GPU available. Switching to CPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T08:27:52.652479Z","iopub.execute_input":"2024-01-02T08:27:52.653152Z","iopub.status.idle":"2024-01-02T08:27:52.660311Z","shell.execute_reply.started":"2024-01-02T08:27:52.653102Z","shell.execute_reply":"2024-01-02T08:27:52.659333Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of available GPUs: 1\nGPU 0: Tesla P100-PCIE-16GB\nCurrent GPU device: 0\nGPU Properties:\n_CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch \nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:03:16.787842Z","iopub.execute_input":"2024-01-02T09:03:16.788387Z","iopub.status.idle":"2024-01-02T09:03:16.792532Z","shell.execute_reply.started":"2024-01-02T09:03:16.788351Z","shell.execute_reply":"2024-01-02T09:03:16.791583Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing a Tensor","metadata":{}},{"cell_type":"markdown","source":"## Directly from data","metadata":{}},{"cell_type":"code","source":"data = [[1,2],[3,4]]\n\nx_data = torch.tensor(data)\nprint(type(data))\nprint(type(x_data))\nx_data.device","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:07:03.722432Z","iopub.execute_input":"2024-01-02T09:07:03.723144Z","iopub.status.idle":"2024-01-02T09:07:03.730909Z","shell.execute_reply.started":"2024-01-02T09:07:03.723098Z","shell.execute_reply":"2024-01-02T09:07:03.729953Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'list'>\n<class 'torch.Tensor'>\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"data = [[1,2],[3,4]]\n\nx_data = torch.tensor(data,device = 'cuda')\nprint(type(data))\nprint(type(x_data))\nx_data.device","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:06:51.734338Z","iopub.execute_input":"2024-01-02T09:06:51.734941Z","iopub.status.idle":"2024-01-02T09:06:51.742877Z","shell.execute_reply.started":"2024-01-02T09:06:51.734908Z","shell.execute_reply":"2024-01-02T09:06:51.741934Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"<class 'list'>\n<class 'torch.Tensor'>\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"torch.rand(3,3)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:14:33.971185Z","iopub.execute_input":"2024-01-02T09:14:33.971874Z","iopub.status.idle":"2024-01-02T09:14:33.980539Z","shell.execute_reply.started":"2024-01-02T09:14:33.971839Z","shell.execute_reply":"2024-01-02T09:14:33.979531Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([[0.0108, 0.0864, 0.4513],\n        [0.7644, 0.8499, 0.8241],\n        [0.2996, 0.8220, 0.9063]])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Basic Tensor operation","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:18:25.905547Z","iopub.execute_input":"2024-01-02T09:18:25.906244Z","iopub.status.idle":"2024-01-02T09:18:25.910351Z","shell.execute_reply.started":"2024-01-02T09:18:25.906209Z","shell.execute_reply":"2024-01-02T09:18:25.909341Z"}}},{"cell_type":"code","source":"device = 'cpu'\n\nif torch.cuda.is_available():\n    device = 'cuda'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:20:52.278308Z","iopub.execute_input":"2024-01-02T09:20:52.279048Z","iopub.status.idle":"2024-01-02T09:20:52.285328Z","shell.execute_reply.started":"2024-01-02T09:20:52.279017Z","shell.execute_reply":"2024-01-02T09:20:52.284387Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"a = torch.randn(5,7)  # creating in cpu\n\na = a.to(device) # transfering to gpu\nprint(a.device)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:24:31.041215Z","iopub.execute_input":"2024-01-02T09:24:31.042045Z","iopub.status.idle":"2024-01-02T09:24:31.048044Z","shell.execute_reply.started":"2024-01-02T09:24:31.042009Z","shell.execute_reply":"2024-01-02T09:24:31.047068Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}